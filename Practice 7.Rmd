---
title: "Lab 7"
output: html_document
date: "2024-04-28"
---
Question 1 SLR in a matrix form
The data below show the number of competing loan companies operating in the city (X) and the number of loans (per thousand) made in that city that are currently delinquent (Y):
```{r}
X = c(4,1,2,3,3,4)
Y = c(16, 5, 10, 15, 13, 22)
```
Formulate the matrices X,Y and the SLR model equation based on the data.
```{r}
X = c(4, 1, 2, 3, 3, 4)
Y = c(16, 5, 10, 15, 13, 22)  ## vec Y
One = c(1, 1, 1, 1, 1, 1)
Xmat = cbind(One, X)  ## matrix X
Xmat
Y
```

(b) Calculate the matrices multiplications using R for Y' Y,X' X.
```{r}
YtY = t(Y) %*% Y  ## Y'Y matrix multiplication %*%
YtY
```
```{r}
XtX = t(Xmat) %*% Xmat  ## X'X 2x2 matrix
XtX
invX = solve(XtX)
invX
check = (XtX) %% invX
check
```
(c).Calculate the estimates of Œ≤1 using the above matrix formula in R.
```{r}
betahat = solve(XtX) %*% t(Xmat) %*% Y
betahat
```
Find œµÃÇ T,SSE and œÉÃÇ^ 2.
```{r}
Yhat = Xmat %*% betahat

```
Question 2L Gasoline.csv
(a). Fit a multiple linear regression model relating gasoline mileage (y) (miles per gallon) to engine displacement (x1) and the number of carburetor barrels (x6).
```{r}
Gasoline = read.csv("Gasoline.csv", header = T)
head(Gasoline)
M2 = lm(y ~ x1 + x6, data = Gasoline)
summary(M2)
```
ùö¢ÀÜ=32.884551‚àí0.053148ùö°ùü∑+0.959223x6

Step 1:
H0: Œ≤1=Œ≤2=0
H1: Not H0

Step 2 F Test
F Test from the table is 53.67. In simple terms, it quantifies how much better the regression model fits the data compared to a model with no predictors (i.e., an intercept-only model). Higher values of the F-statistic indicate a better fit of the model to the data.

Step 3: DF
2 and 29.
2 means 2 predictors. b1 and b2
29 means 29 degrees of freedom associated with the residual error. 

Step 4: p-value
Since p-value: 1.79e-10 is lesser than 5% of significant. Hence, we reject null hypothesis.

Step 5: Conclusion
Given the results of the F-test and associated p-value, we reject the null hypothesis that both predictors b1 and b2 have no effect on the dependent vairiable. The suggests that at least one of the predictors has a statistically significant effect on the dependent variable.

Step 6: Decision
Therefore, we have sufficient evidence to conclude that there is a significant relationship between the predictors and the dependent variable. In other words, the regression model provides a better fit to the data compared to a model with no predictors (intercept-only model). Consequently, we accept the alternative hypothesis, indicating that there is evidence to support the claim that the predictors collectively contribute to explaning the variation in the dependent variable. 

In summary, based on the analysis conducted, we reject null hypothesis and accept the alternative hypothesis, affirming that there is a statistically significant relationship between the predictors and the dependent variable in the regression model.

(c) Test whether the variable x6 is statistically significant at the level 5% given the present of the variable x1.



(d) Determine a 95% CI for the regression coefficient of x1.
```{r}
confint(M2, level = 0.95) #confint is used to calculate confience intervals for the coefficients of a linear regression model.
```
The 95% CI for x1 is ( -0.06569892, -0.04059641 )

Once you have the table showing the confidence intervals for the coefficients of your regression model, you can use this information to make inferences about the population parameters and the significance of the predictors.

Here's what you can do with the output:

Interpretation of Confidence Intervals: Each row in the table represents one coefficient in the regression model. The columns "2.5%" and "97.5%" provide the lower and upper bounds of the 95% confidence interval for each coefficient. If the confidence interval includes zero, it suggests that the corresponding coefficient is not significantly different from zero at the 5% significance level. On the other hand, if the interval does not include zero, it suggests that the coefficient is statistically significant.

Assessment of Significance: For example, in your output:
The confidence interval for the intercept ranges from approximately 29.74 to 36.02.
The confidence interval for the coefficient of "x1" ranges from approximately -0.0657 to -0.0406.
The confidence interval for the coefficient of "x6" ranges from approximately -0.4116 to 2.3301.

Decision Making: Based on the confidence intervals, you can determine whether each predictor is statistically significant. If the interval does not include zero, you can conclude that the corresponding predictor has a statistically significant effect on the dependent variable at the chosen significance level.

Model Interpretation: These intervals provide a range of plausible values for the coefficients. You can use this information to interpret the relationships between the independent variables and the dependent variable. For example, if the confidence interval for the coefficient of a predictor is entirely negative, it suggests a negative relationship with the dependent variable.

In summary, the confidence intervals allow you to assess the uncertainty associated with the estimated coefficients and make informed decisions about the significance of predictors in your regression model.


Question 3
(a). Perform exploratory data analysis on the data using scatter plot matrix and boxplots.
```{r}
nyc = read.csv("nyc.csv")
View(nyc)
head(nyc)
```
```{r}
nyc1=nyc[,c(-1,-2,-7)]
nyc$East = factor(nyc$East)
head(nyc)
pairs(nyc1)
library(PerformanceAnalytics)
chart.Correlation(nyc1)
```

Histogram: The variables price and Foods have symmetric shapes, Decor has a skewed to the left and Service has a bimodal shape (ÈõôÂ≥∞ÂΩ¢ÁãÄ).

Scatterplots: Price has a quite linear positive relationship with Decor(Ë£ùÊΩ¢), but more variations relationships with Food and Services. Food has a positive relationship with Decor and Service, while Service and Decor has the most scattered relationship with 3 likely outliers at the end.

```{r}
par(mfrow = c(2, 2))
boxplot(Price ~ East, data = nyc, xlab = "1=East, 0=West")
boxplot(Food ~ East, data = nyc)
boxplot(Decor ~ East, data = nyc)
boxplot(Service ~ East, data = nyc)
```
In all these side by side boxplots, restaurants in the East has higher Price, Food, Decor and Service in terms of the median ratings. These shapes distribution of East are symmetric with similar spreads to West.

```{r}
library(scatterplot3d)
with(nyc,{
  scatterplot3d(x = Decor, y = Food, z = Price, main = "3-D Scatterplot")
})
```
```{r}
library(scatterplot3d)
with(nyc, {
  s3d <- scatterplot3d(x=Decor, y=Food, z=Price, color = "blue", pch = 19,
                       type = "h", main = "3-D Scatterplot", xlab = "Decor", ylab = "Food", zlab = "Price")
  s3d.coords <- s3d$xyz.convert(Decor, Food, Price)
  
  text(s3d.coords$x, s3d.coords$y, labels = row.names(nyc), cex=0.5, pos = 4)
})
```
(b). Develop a regression model that directly predicts the price of dinner (in dollars) using a subset or all of the 4 potential predictor variables listed above.
```{r}
ny.lm = lm(Price ~ Food + Decor + Service + East, data = nyc)
summary(ny.lm)
```
The initial regression model is 

Price = -24.02 + 1.53Food + 1.91 Decor -0.03 Service + 2.07 East

At this point we shall leave the variable Service in the model though its regression coefficient is not statistically significant. ?

(c) Explain the fitted model, by interpreting the slopes and intercept.
```{r}
ny1.lm <- lm(Price ~ Food + Decor + East, data = nyc) # ?
summary(ny1.lm)
```
The final regression model is:

Price = -24.03 + 1.54 Food + 1.91 Decor + 2.07East 

b0: -24.03 Not interpretable 
b1 = 1.54 Assuming Decor and East are constants, for every 1 unit increase in Food, Price will add up 1.54.
b2 = 1.91 Assuming Food and East are constant, for every 1 unit increase in Decor, Price will increase 1.91
b3 = 2.07 Assuming Food and Decor are constant, for every 1 unit increase in East, Price will increase 2.07.

Comparing the last two sets of output from R, we see that the regression coefficients for the variables in both models are very similar. This does not always occur.

Perform hypothesis testing about H0:Œ≤j=0
 against H1:Œ≤j‚â†0
 for j=0,1,...,3.
The solution is provided for Œ≤1
. Please repeat the steps for other parameters.

6 steps hypothesis testing for Œ≤1
:

H0:Œ≤1=0,H1:Œ≤1‚â†0

The test statistic (from R output as in the above):

t=Œ≤ÃÇ 1‚àí0se(Œ≤ÃÇ 1)=1.53630.2632=5.838.

The sampling distribution for the test statistic is t
 is Tdf=(n‚àíp‚àí1)
 that is Tdf=168‚àí3‚àí1=164.

The p-value = 2.76e-08 (from the R ouput)

Decision. Given the p-value is very small, less than the significance level, then we strongly reject the null hypothesis.

Conclusion. We conclude that the slope is statistically significantly different to zero.


(e). Determine which of the predictor variables Food, D√©cor and Service has the largest estimated effect on Price? Is this effect also the most statistically significant?

++ The variable D√©cor has the largest effect on Price since its regression coefficient is largest. Note that Food, D√©cor and Service are each measured on the same 0 to 30 scale and so it is meaningful to compare regression coefficients.(? how to find coefficient)


++ The variable D√©cor is also the most statistically significant since its p -value is the smallest of the three.

(f) Based on the R output, estimate œÉ2.

```{r}
names(summary(ny1.lm))
s = summary(ny1.lm)$sigma
cat("Sigma is", s)
s2 = s^2
cat("The S square is", s2)
```
The estimate for sigma square is 32.7227.

(g) If the aim is to choose the location of the restaurant so that the price achieved for dinner is maximized, should the new restaurant be on the east or west of Fifth Avenue?

In order that the price achieved for dinner is maximised, the new restaurant should be on the east of Fifth Avenue since the coefficent of the dummy variable is statistically significantly larger than 0.


(h) Does it seem possible to achieve a price premium for "setting a new standard to service in Manhattan" for Italian restaurants?

It does not seem possible to achieve a price premium for ‚Äúsetting a new standard for high quality service in Manhattan‚Äù for Italian restaurants since the regression coefficient of Service is not statistically significantly greater than zero.


Question 4 Salary Data

a. Perform exploratory data analysis on the data using scatter plot matrix and boxplots.
```{r}
salary = read.csv("salary.csv", header = TRUE)
head(salary)
library(PerformanceAnalytics)
pairs(salary)
chart.Correlation(salary)
```
```{r}
library(scatterplot3d)
with(salary, {
  s3d <- scatterplot3d(x = experience, y = publish, z = salary, color = "orange",
                       pch = 19, type = "h", main = "3-D Scatterplot", xlab = "Experience", ylab = "Publish", zlab = "Salary") #How to find which one is xyz?
  
  # Convert 3-D coords to 2D projection
  s3d.coords <- s3d$xyz.convert(salary, experience, publish)
  
  #plot text with 50% shrink and place to right of points
  text(s3d.coords$x, s3d.coords$y, labels = row.names(salary), cex = 0.5, pos = 4)
  
})
```
(b) fit the linear regression model of salary on experience, quality and publish, Write down the estimated regression line and interpret the model.

```{r}
salary.lm <- lm(salary ~ experience + quality + publish , data = salary)
summary(salary.lm)
```
The fitted formular is

Salary = 17.847 + 0.32152 Exprience + 1.10 quality + 1.289 publish

b0: 17.847 not interceptable
b1: 0.32152 Assuming quality and publish are constant, 1 unit of experience increase, the salary will increase 0.32
b2: 1.10. Assuming experience and publish are constant, 1 unit of quality increase, the salary will increase 1.10
b3: 1.29. Assuming experience and quality are constant, 1 unit of public increase, the salary will increase 1.29

(c). Obtain the estimates of œÉ2,var(Œ≤)
```{r}
names(summary(salary.lm))
s = summary(salary.lm)$sigma

s2 = s^2
s2
```
```{r}
X <- as.matrix(salary[,-1])
X <- cbind(1,X)
head(X)
XtX = t(X) %*% X
invX = solve(XtX)
varcov = invX * s2
varcov
```
Question 5
The data frame Defects provides data on the average number of defects per 1000 parts (Defective) produced in an industrial process along with the values of other variables (Temperature, Density, and Rate). The production engineer wishes to construct a linear model relating Defective to the potential predictors.

(a) Use the pairs function to produce a scatterplot matrix of all the variables in Defects. Are the scatterplots of Defective against the other variables linear?
```{r}
defects <- read.table("defects.txt", header = T)
defects <- defects[,-1]
head(defects)
pairs(defects)
library(PerformanceAnalytics)
chart.Correlation(defects)
```

```{r}
defects.lm <- lm(Defective ~ Rate + Density + Temperature, data = defects)
summary(defects.lm)
```

Defective= 10.3244 + 0.1167 Rate -1.8273 Density + 16.0779 Temperature
Nothing that all of the variables are not significant at 5% level